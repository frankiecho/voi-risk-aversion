---
title: "Value of information of a risk-averse expected utility maximiser"
output: html_notebook
author: Frankie Cho
---

The aim of this paper is to analyse the decisions and choices of a decision-maker when faced with an uncertain prospect and aims to choose whether to (a) act under uncertainty, or (b) undertake an experiment to reduce or eliminate uncertainty. Such a problem has broad applications ranging from the optimal monitoring of species (in ecological application), to applications in medicine to determine whether it is optimal to invest in life-saving medical treatments, or invest in other uncertainty-reducing scientific research.

The analysis of such is typically done using the Value of Information framework, which postulates that the information that is gained through the experiment is the difference between the expected value of the outcomes if the decision-maker resolved the uncertainty and acted to maximise such information, relative to the expected value of the outcomes if the decision-maker does not have the information afforded by the experiment. The value of expected perfect information (EVPI) is typically calculated through this equation:

$$
EVPI=\mathbb{E}_s[\max_a U(a,s) ] - \max_a \mathbb{E}_s [U(a,s)]
$$ Where $s$ are states of the system that the decision-maker is uncertain about before undertaking that experiment (and becomes certain about after the experiment), $a$ is the action that the decision-maker undertakes, and $u$ is the utility function that is jointly determined by the action undertaken by the decision-maker and the state in which the system is in.

To simplify our characterisation, we call the first part of this equation the value of the system under certainty $V_{certainty}$, and the second part of this equation the value of the system under uncertainty $V_{uncertainty}$, using the same notation as Akinlotan et al. (in review). The difference between these two values is the value of the information that the decision-maker gains from the experiment.

Typical assessments of the Value of Information framework assumes that the decision-maker is risk-neutral, with their marginal levels of utility increasing in the same amounts whichever their level of utility is. It is unclear whether a decision-maker will have different levels of the EVPI if they hold risk-averse (or risk-loving) attitudes. To my knowledge, there has not been work that analyses how this changes when a decision-maker adopts risk-averse preferences.

In economics, the dominant approach for analysing behaviours' of decisions made under uncertainty has been to use the von Neumann-Morgenstern Expected Utility Theory (EUT). In essence, the theory predicts that decision-makers maximise the following when faced with choices under uncertainty, following consistent notation:

$$
EU = \max_a \mathbb{E}_s [U(a,s)]
$$ which predicts that a decision-maker faced with uncertainty will choose $a$ to maximise the expected utility across all states. This is the same case as the second part of the EVPI equation.

A point of departure of economic theory is that it postulates that an individual's utility for payoffs is weighted by their risk-attitude, which is typically modeled by a continuous utility function. The most common utility function used in economics is the Constant Relative Risk Aversion (CRRA) utility function, which is defined as:

$$
U_\gamma(c(a,s)) = \begin{cases} \frac{c(a,s)^{1-\gamma}}{1-\gamma} \quad \text{for} \quad \gamma \neq 1 \\ \log(c(a,s)) \quad \text{for} \quad \gamma=1 \end{cases}
$$ where $c$ is the payoff written a function of $a$ and $s$, and $\gamma$ is the coefficient of relative risk aversion. The CRRA utility function is a generalisation of the logarithmic utility function, which is the case when $\gamma=1$. The utility function is more risk-averse when $\gamma>1$, less risk-averse when $\gamma<1$ and risk-neutral when $\gamma=0$. The gamma parameter controls the curvature of the utility function which dictates the marginal amount of increase in utility for every unit of increase in the payoff. A high value for $\gamma$ means that the decision-maker is more risk-averse, with marginal increases in payoffs leading to high increases in utility at low levels of payoffs, and much smaller marginal increases in utility at high levels of payoffs. Empirical evidence points to this coefficient to be between 1 and 3, with the most common value being 2 (e.g. Groom and Maddison, 2019).

A useful concept would be to re-frame expected utility into certainty equivalents, which is defined as the amount of payoff (in certainty) that is needed to a decision-maker (with a given level of risk-aversion) to be indifferent between having the uncertain, random outcome and the certain outcome. The certainty equivalent of a payoff $c$ is defined as follows:

$$
CE_\gamma = U^{-1}_\gamma (\mathbb{E}_s [U_\gamma(c)])
$$

where $U^{-1}$ is the functional inverse of the utility function.

If framed as an expected utility problem, a decision-maker adopting a VoI framework for making decisions over whether to undertake an experiment to reduce uncertainty faces a choice between two uncertain prospects. In particular, the risk aversion parameter alters two key components in the EVPI calculation (later generalised to cases of partial information). First, in the $v_{\text{certainty}}$ term, it alters the expected utility of the system under certainty; given that it is uncertain which state the decision-maker is currently in, the decision-maker faces a distribution of possible payoffs after resolving uncertainty (the $\max_a U(a,s)$ terms across all of $s$), and weighs this (at this point) uncertain distribution of payoffs according to their risk aversion. Second, in the $v_{\text{uncertainty}}$ term, the level of risk aversion alters both the decision-makers' value of the uncertain system and the decision-makers' optimal management action under uncertainty. Particularly, the risk-averse decision-maker no longer opts for an action that leads to the highest expected payoff; rather, they opt for one that minimises their chances of reaching a very low outcome.

The aim of this paper is to analyse the value of information of a decision-maker who is a risk-averse expected utility maximiser. The paper will use the CRRA utility function to model the decision-maker's preferences, and will compare the value of information of a risk-averse decision-maker to that of a risk-neutral decision-maker. The paper will also analyse how the value of information changes as the decision-maker's risk-attitude changes.

## Two-state, two-action example

We begin to consider a simple two-state, two-action example, with the following payoffs:

|          | State 1 (p=0.5) | State 2 (p=0.5) |
|----------|-----------------|-----------------|
| Action 1 | 1               | 1               |
| Action 2 | 1.5             | 0.9             |

Here, it is clear that Action 2 leads to higher payoffs on average (1.2), but Action 1 leads to the certain outcome of 1 irrespective of how the experiment turns out. How many units will the decision-maker be willing to pay to obtain information that resolves uncertainty about these states?

```{r}
library(ggplot2)
library(LaplacesDemon)
library(mvtnorm)
library(reshape2)
library(tidyverse)
library(PerformanceAnalytics)

source("~/Documents/GitHub/voi-risk-aversion/code/voi_simulations.R")
gamma_seq <- seq(-20,20,.01)
e1 <- list()
n_states <- 2
n_actions <- 2
a1 <- c(1, 1)
a2 <- c(1.5, 0.9)
e1$p <- c(0.5, 0.5)
action_state <- matrix(c(a1, a2), byrow = T, ncol = length(a1))
colnames(action_state) <- paste0('s', 1:n_states)
rownames(action_state) <- paste0('a', 1:n_actions)
e1$action_state <- action_state
fcn_VOI_simulation(e1, gamma_seq) %>%
  ggplot(aes(x = gamma, y = VPI, color = factor(max_EU))) +
  geom_line() +
  theme_minimal()
```

Here, we observe the EVPI and the optimal choice of action made by the decision-maker under uncertainty represented by the color of the line. Action 2 has 0.2 higher expected payoffs (under uncertainty), but Action 1 does not have a state of low payoffs (payoff=0.9).

As we can see in this simple example, the decision-maker is willing to pay 0.05 units for information that resolves uncertainty under the risk-averse case. But notice that this value changes depending on his/ her risk aversion.

First, notice that the decision-maker is willing to pay less information if he/ she is risk-averse. This is because if he/ she is risk-loving, he/ she will choose Action 2 regardless (weighing the outcome of 1.5 payoff much stronger), making his/ her action the same regardless of the outcome of the experiment. If the decision-maker chooses the same action before and after resolving uncertainties, then EVPI=0.

Second, notice that the value of information actually increases at mild risk-aversion, peaking at nearly 0.1. Here, the decision-maker is much more averse to low payoffs (i.e. 0.9). By resolving uncertainty, the decision-maker can eliminate the prospect of reaching payoffs equal to 0.9 by choosing Action 1 under State 1 (payoff=1) and Action 2 under State 2 (payoff=1.5). In such cases, he/ she will prefer information even more than the risk-neutral decision-maker.

However, notice also that the EVPI declines after certain levels of increases in the risk aversion coefficient. At a certain level (in this case, at $\gamma=7$), the optimal action under uncertainty will be Action 1, because the decision-maker is strongly averse to payoff equal to 0.9 that he/ she chooses to do the action that avoids that undesirable outcome (payoff = 0.9) even though he/ she misses out on the prospect of payoffs = 1.5.

But also notice that the value of information actually declines as we push to even more risk-averse preferences. This is because the marginal increases in utility for gaining more information (obtaining the distribution of payoffs at 1 and 1.5) relative to acting under uncertainty (certain payoff at 1 by choosing Action 2) declines. This means that gaining more information leads to less gains in utility as risk aversion increases.

As we can see in the diagram below, the certainty-equivalent of the Actions 1 and 2 under uncertainty changes with respect to the risk aversion coefficient; in $\gamma=7$ the certainty-equivalent of Action 2 drops below Action 1.

```{r}

e1_ce <- lapply(gamma_seq, function(gamma) apply(CARA(e1$action_state, gamma) %*% e1$p, 1, 
                                        function(x) CARA_inv(x, gamma))) %>%
  bind_rows()
e1_ce$gamma <- gamma_seq
e1_ce %>%
  pivot_longer(paste0('a', 1:n_actions), names_to = 'actions', values_to = 'ce') %>%
  ggplot(aes(y = ce, x = gamma, color = actions))+
  geom_line()+
  theme_minimal()

```

This yields two important insights. First, under certain levels of risk aversion the VoI of a risk-averse decision-maker could be higher than that of a risk-neutral decision-maker. This could potentially resolve a paradox where it was found that the VoI is consistently low (Holden et al., in review), yet billions were continually spent in ecosystem monitoring and research. Is it because the decision-makers are risk-averse? Second, the increase in VoI relative to the coefficient of risk aversion is non-linear, meaning that it could decline and peak at certain points of risk-aversion. This makes it impossible to derive generalisable conclusions by the use of a simple two-action, two-state example.

## Many-state, many-action example

[to continue from the voi_problems.R example]
